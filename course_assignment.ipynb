{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca1cc7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function , J(1,3) = 12.375\n",
      "********************************************************************************\n",
      "Original ceta0 is 1\n",
      "Original ceta1 is 3\n",
      "****************************************\n",
      "Gradiant descent iterations:\n",
      "iteration 1\n",
      "ceta0 = 0.993\n",
      "ceta1 = 2.47625\n",
      "iteration 2\n",
      "ceta0 = 0.986\n",
      "ceta1 = 1.9524999999999997\n",
      "iteration 3\n",
      "ceta0 = 0.979\n",
      "ceta1 = 1.4287499999999995\n",
      "iteration 4\n",
      "ceta0 = 0.972\n",
      "ceta1 = 0.9049999999999995\n",
      "iteration 5\n",
      "ceta0 = 0.965\n",
      "ceta1 = 0.3812499999999994\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def gd(x, y, c0=1, c1=3, lr=0.002, iter=1):\n",
    "    #calculate rows \n",
    "    rows = 0\n",
    "    for i in x:\n",
    "        rows += 1\n",
    "\n",
    "    i = 0\n",
    "    half_cost_fun = [] #This list to store the values of (h(x)-(y))**2\n",
    "    half_cost_fun_without_power = [] #This list to store the values of (h(x)-(y))\n",
    "    half_cost_fun_times_x = [] #This list to store the values of (h(x)-(y))*x\n",
    "    for n in x:\n",
    "        predict_value = c0 + c1 * x[i] #calculate predict value\n",
    "        \n",
    "        part_of_cost_f = (predict_value - y[i])**2 #(h(x)-(y))**2 to calculate cost function = 1/2m * sum((h(x)-(y))**2)\n",
    "        half_cost_fun.append(part_of_cost_f)\n",
    "        \n",
    "        part_of_cost_f_without_power = (predict_value - y[i])#(h(x)-(y)) used it in gradient descent to reduce ceta 0\n",
    "        half_cost_fun_without_power.append(part_of_cost_f_without_power)\n",
    "        \n",
    "        part_of_cost_f_times_x = (predict_value - y[i])*x[i]#(h(x)-(y))*x used it in gradient descent to reduce ceta 1\n",
    "        half_cost_fun_times_x.append(part_of_cost_f_times_x)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "        \n",
    "    cost_fun = 1 / (2 * rows) * sum(half_cost_fun) #claculate cost function\n",
    "    print(f\"cost function , J({c0},{c1}) = {cost_fun}\")\n",
    "    \n",
    "    print(\"*\" * 80)\n",
    "\n",
    "    print(f\"Original ceta0 is {c0}\")\n",
    "    print(f\"Original ceta1 is {c1}\")\n",
    "    \n",
    "    print(\"*\" * 40)\n",
    "\n",
    "\n",
    "    print(f\"Gradiant descent iterations:\")\n",
    "    while 6 > iter:\n",
    "        c0 = c0 - lr * 1 / rows * sum(half_cost_fun_without_power) #calcualate gradient descent for ceta 0\n",
    "        c1 = c1 - lr * 1 / rows * sum(half_cost_fun_times_x) #calcualate gradient descent for ceta 1\n",
    "        print(f\"iteration {iter}\")\n",
    "        print(f\"ceta0 = {c0}\")\n",
    "        print(f\"ceta1 = {c1}\")\n",
    "        iter += 1\n",
    "\n",
    "    \n",
    "gd(x = [100, 95,90,80,80,70,70,60], y = [300, 285, 270, 240, 235, 200, 205, 180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e84aa96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function , J(0.3198248514164548,0.4789199890834046) = 275.3409882929944\n",
      "********************************************************************************\n",
      "Original ceta0 is 0.3198248514164548\n",
      "Original ceta1 is 0.4789199890834046\n",
      "****************************************\n",
      "Gradiant descent iterations:\n",
      "iteration 1\n",
      "ceta0 = 0.3589170818337044\n",
      "ceta1 = 0.7685250765584015\n",
      "iteration 2\n",
      "ceta0 = 0.39800931225095404\n",
      "ceta1 = 1.0581301640333984\n",
      "iteration 3\n",
      "ceta0 = 0.43710154266820367\n",
      "ceta1 = 1.3477352515083953\n",
      "iteration 4\n",
      "ceta0 = 0.4761937730854533\n",
      "ceta1 = 1.6373403389833923\n",
      "iteration 5\n",
      "ceta0 = 0.5152860035027029\n",
      "ceta1 = 1.9269454264583892\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def gd(x, y, c0=random.random(), c1=random.random(), lr=0.002, iter=1):\n",
    "    #calculate rows \n",
    "    rows = 0\n",
    "    for i in x:\n",
    "        rows += 1\n",
    "\n",
    "    i = 0\n",
    "    half_cost_fun = [] #This list to store the values of (h(x)-(y))**2\n",
    "    half_cost_fun_without_power = [] #This list to store the values of (h(x)-(y))\n",
    "    half_cost_fun_times_x = [] #This list to store the values of (h(x)-(y))*x\n",
    "    for n in x:\n",
    "        predict_value = c0 + c1 * x[i] #calculate predict value\n",
    "        \n",
    "        part_of_cost_f = (predict_value - y[i])**2 #(h(x)-(y))**2 to calculate cost function = 1/2m * sum((h(x)-(y))**2)\n",
    "        half_cost_fun.append(part_of_cost_f)\n",
    "        \n",
    "        part_of_cost_f_without_power = (predict_value - y[i])#(h(x)-(y)) used it in gradient descent to reduce ceta 0\n",
    "        half_cost_fun_without_power.append(part_of_cost_f_without_power)\n",
    "        \n",
    "        part_of_cost_f_times_x = (predict_value - y[i])*x[i]#(h(x)-(y))*x used it in gradient descent to reduce ceta 1\n",
    "        half_cost_fun_times_x.append(part_of_cost_f_times_x)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "        \n",
    "    cost_fun = 1 / (2 * rows) * sum(half_cost_fun) #claculate cost function\n",
    "    print(f\"cost function , J({c0},{c1}) = {cost_fun}\")\n",
    "    \n",
    "    print(\"*\" * 80)\n",
    "\n",
    "    print(f\"Original ceta0 is {c0}\")\n",
    "    print(f\"Original ceta1 is {c1}\")\n",
    "    \n",
    "    print(\"*\" * 40)\n",
    "\n",
    "\n",
    "    print(f\"Gradiant descent iterations:\")\n",
    "    while 6 > iter:\n",
    "        c0 = c0 - lr * 1 / rows * sum(half_cost_fun_without_power) #calcualate gradient descent for ceta 0\n",
    "        c1 = c1 - lr * 1 / rows * sum(half_cost_fun_times_x) #calcualate gradient descent for ceta 1\n",
    "        print(f\"iteration {iter}\")\n",
    "        print(f\"ceta0 = {c0}\")\n",
    "        print(f\"ceta1 = {c1}\")\n",
    "        iter += 1\n",
    "\n",
    "    \n",
    "gd(x = [1,2,3,4,5,6,7,8,9,10], y = [0,5,10,15,20,25,30,35,40,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa8b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
